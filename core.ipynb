{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe70ed6",
   "metadata": {},
   "source": [
    "### 🧱 Step 1: Audio I/O (Hear & Speak Back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261c3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08063423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "duration = 3   # seconds\n",
    "fs = 16000     # sample rate (16 kHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb67ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Recording... Speak now!\n",
      "✅ Recording complete!\n",
      "🔊 Playing back your voice...\n",
      "🎉 Done! That’s your voice.\n"
     ]
    }
   ],
   "source": [
    "print(\"🎤 Recording... Speak now!\")\n",
    "recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "sd.wait()  # wait until done\n",
    "print(\"✅ Recording complete!\")\n",
    "\n",
    "# Save as a file (optional)\n",
    "wav.write(\"Recordings/whispy_test.wav\", fs, recording)\n",
    "\n",
    "# Playback\n",
    "print(\"🔊 Playing back your voice...\")\n",
    "sd.play(recording, fs)\n",
    "sd.wait()\n",
    "print(\"🎉 Done! That’s your voice.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24ce0e",
   "metadata": {},
   "source": [
    "### 🧱 Step 2: Whispy learns to understand words (STT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fcb239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vosk model\n",
    "model = Model(\"model\")\n",
    "recognizer = KaldiRecognizer(model, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0312832",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303084af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    q.put(bytes(indata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e2cd263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Whispy is listening... Say something! (say 'stop' to quit)\n",
      "📝 Whispy heard: dave\n",
      "📝 Whispy heard: so how are you will be\n",
      "📝 Whispy heard: they heard would miss him smuggled they've who is dave\n",
      "📝 Whispy heard: no no no no way to his me\n",
      "📝 Whispy heard: know your name is was be lucky that help our yeah that tackling your name is ray speak\n",
      "📝 Whispy heard: it is was no no wait wait wait\n",
      "📝 Whispy heard: the guy as a way to it can we start from over\n",
      "📝 Whispy heard: what a fuck man\n",
      "📝 Whispy heard: we're lucky caligula in the way that either subassembly told to shake it has been this got that stop\n",
      "👋 Whispy says: Bye Mansour!\n"
     ]
    }
   ],
   "source": [
    "# Open microphone stream\n",
    "with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',\n",
    "                       channels=1, callback=callback):\n",
    "\n",
    "    print(\"🎤 Whispy is listening... Say something! (say 'stop' to quit)\")\n",
    "\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            text = result[\"text\"]\n",
    "            if text:\n",
    "                print(\"📝 Whispy heard:\", text)\n",
    "                if \"stop\" in text.lower():\n",
    "                    print(\"👋 Whispy says: Bye Mansour!\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd8746",
   "metadata": {},
   "source": [
    "### 🧱 Step 3: Whispy Talks Back (TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7b1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "import pyttsx3\n",
    "from vosk import Model, KaldiRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26011ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vosk model\n",
    "model = Model(\"model\")\n",
    "recognizer = KaldiRecognizer(model, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fd1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS engine\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1517e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4214e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    q.put(bytes(indata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f2c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    print(\"🗣️ Whispy says:\", text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab69b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ Whispy says: Hello Mansour! I am Whispy. Say something. Say stop to quit.\n",
      "📝 Whispy heard: hi\n",
      "🗣️ Whispy says: I heard you say hi\n",
      "📝 Whispy heard: hello\n",
      "🗣️ Whispy says: Hello! Nice to hear you.\n",
      "📝 Whispy heard: where\n",
      "🗣️ Whispy says: I heard you say where\n",
      "📝 Whispy heard: he knew service where are you now\n",
      "🗣️ Whispy says: I heard you say he knew service where are you now\n",
      "📝 Whispy heard: ha\n",
      "🗣️ Whispy says: I heard you say ha\n",
      "📝 Whispy heard: what are you doing\n",
      "🗣️ Whispy says: I heard you say what are you doing\n",
      "📝 Whispy heard: can you reply\n",
      "🗣️ Whispy says: I heard you say can you reply\n",
      "📝 Whispy heard: useless\n",
      "🗣️ Whispy says: I heard you say useless\n",
      "📝 Whispy heard: i didn't say is was\n",
      "🗣️ Whispy says: I heard you say i didn't say is was\n",
      "📝 Whispy heard: stop\n",
      "🗣️ Whispy says: Goodbye Mansour, see you soon!\n"
     ]
    }
   ],
   "source": [
    "# Open microphone stream\n",
    "with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',\n",
    "                       channels=1, callback=callback):\n",
    "\n",
    "    speak(\"Hello Mansour! I am Whispy. Say something. Say stop to quit.\")\n",
    "\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            text = result[\"text\"]\n",
    "            if text:\n",
    "                print(\"📝 Whispy heard:\", text)\n",
    "\n",
    "                if \"stop\" in text.lower():\n",
    "                    speak(\"Goodbye Mansour, see you soon!\")\n",
    "                    break\n",
    "                elif \"hello\" in text.lower():\n",
    "                    speak(\"Hello! Nice to hear you.\")\n",
    "                elif \"your name\" in text.lower():\n",
    "                    speak(\"My name is Whispy. I am your voice assistant.\")\n",
    "                else:\n",
    "                    speak(\"I heard you say \" + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57590aae",
   "metadata": {},
   "source": [
    "### 🧱 Step 4: Add App/Website Commands 🌐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e571d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "import pyttsx3\n",
    "import webbrowser\n",
    "from vosk import Model, KaldiRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4550b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vosk model\n",
    "model = Model(\"model\")\n",
    "recognizer = KaldiRecognizer(model, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3591c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS engine\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcb77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba12dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    q.put(bytes(indata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3065c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    print(\"🗣️ Whispy says:\", text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2ff544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ Whispy says: Hello Mansour! I am Whispy. Say a command. Say stop to quit.\n",
      "📝 Whispy heard: can you\n",
      "🗣️ Whispy says: I heard you say can you\n",
      "📝 Whispy heard: can you have a you tube of content on you tube time religion\n",
      "🗣️ Whispy says: Opening YouTube for you!\n",
      "📝 Whispy heard: oh older than the thank you\n",
      "🗣️ Whispy says: I heard you say oh older than the thank you\n",
      "📝 Whispy heard: can you imagine i get up the tab maybe hello\n",
      "🗣️ Whispy says: Hello! Nice to hear you.\n",
      "📝 Whispy heard: can you are when get her for me\n",
      "🗣️ Whispy says: I heard you say can you are when get her for me\n",
      "📝 Whispy heard: there you know get up get up get up\n",
      "🗣️ Whispy says: Opening GitHub for you!\n",
      "📝 Whispy heard: i will i'll i'll come back and a little eligibility the recommended bus stop the durkan linda sister had\n",
      "🗣️ Whispy says: Goodbye Mansour, see you soon!\n"
     ]
    }
   ],
   "source": [
    "# Open microphone stream\n",
    "with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',\n",
    "                       channels=1, callback=callback):\n",
    "\n",
    "    speak(\"Hello Mansour! I am Whispy. Say a command. Say stop to quit.\")\n",
    "\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            text = result[\"text\"]\n",
    "            if text:\n",
    "                print(\"📝 Whispy heard:\", text)\n",
    "\n",
    "                if \"stop\" in text.lower():\n",
    "                    speak(\"Goodbye Mansour, see you soon!\")\n",
    "                    break\n",
    "\n",
    "                elif \"hello\" in text.lower():\n",
    "                    speak(\"Hello! Nice to hear you.\")\n",
    "\n",
    "                elif \"your name\" in text.lower():\n",
    "                    speak(\"My name is Whispy. I am your voice assistant.\")\n",
    "\n",
    "                elif \"you tube\" in text.lower():\n",
    "                    speak(\"Opening YouTube for you!\")\n",
    "                    webbrowser.open(\"https://www.youtube.com\")\n",
    "\n",
    "                elif \"git hub\" in text.lower() or \"get up\" in text.lower():\n",
    "                    speak(\"Opening GitHub for you!\")\n",
    "                    webbrowser.open(\"https://www.github.com\")\n",
    "\n",
    "                elif \"facebook\" in text.lower():\n",
    "                    speak(\"Opening Facebook for you!\")\n",
    "                    webbrowser.open(\"https://www.facebook.com\")\n",
    "\n",
    "                else:\n",
    "                    speak(\"I heard you say \" + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4afb2",
   "metadata": {},
   "source": [
    "### 🧱 Step 5: Add Time & Date Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e155afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "import pyttsx3\n",
    "import webbrowser\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94d02261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vosk model\n",
    "model = Model(\"model\")\n",
    "recognizer = KaldiRecognizer(model, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c70d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS engine\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5b2fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85625df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    q.put(bytes(indata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dcbe16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    print(\"🗣️ Whispy says:\", text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df566538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ Whispy says: Hello Mansour! I am Whispy. Say a command. Say stop to quit.\n",
      "📝 Whispy heard: my\n",
      "🗣️ Whispy says: I heard you say my\n",
      "📝 Whispy heard: by\n",
      "🗣️ Whispy says: I heard you say by\n",
      "📝 Whispy heard: wow\n",
      "🗣️ Whispy says: I heard you say wow\n",
      "📝 Whispy heard: by goodbye goodbye with be\n",
      "🗣️ Whispy says: Goodbye Mansour, see you soon!\n"
     ]
    }
   ],
   "source": [
    "# Open microphone stream\n",
    "with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',\n",
    "                       channels=1, callback=callback):\n",
    "\n",
    "    speak(\"Hello Mansour! I am Whispy. Say a command. Say stop to quit.\")\n",
    "\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            text = result[\"text\"]\n",
    "            if text:\n",
    "                print(\"📝 Whispy heard:\", text)\n",
    "\n",
    "                if \"stop\" in text.lower() or \"bye\" in text.lower():\n",
    "                    speak(\"Goodbye Mansour, see you soon!\")\n",
    "                    break\n",
    "\n",
    "                elif \"hello\" in text.lower():\n",
    "                    speak(\"Hello! Nice to hear you.\")\n",
    "\n",
    "                elif \"your name\" in text.lower():\n",
    "                    speak(\"My name is Whispy. I am your voice assistant.\")\n",
    "\n",
    "                elif \"youtube\" in text.lower():\n",
    "                    speak(\"Opening YouTube for you!\")\n",
    "                    webbrowser.open(\"https://www.youtube.com\")\n",
    "\n",
    "                elif \"github\" in text.lower():\n",
    "                    speak(\"Opening GitHub for you!\")\n",
    "                    webbrowser.open(\"https://www.github.com\")\n",
    "\n",
    "                elif \"facebook\" in text.lower():\n",
    "                    speak(\"Opening Facebook for you!\")\n",
    "                    webbrowser.open(\"https://www.facebook.com\")\n",
    "\n",
    "                elif \"time\" in text.lower():\n",
    "                    now = datetime.now().strftime(\"%H:%M\")\n",
    "                    speak(f\"The time is {now}\")\n",
    "\n",
    "                elif \"date\" in text.lower():\n",
    "                    today = datetime.now().strftime(\"%A, %B %d, %Y\")\n",
    "                    speak(f\"Today is {today}\")\n",
    "\n",
    "                else:\n",
    "                    speak(\"I heard you say \" + text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
